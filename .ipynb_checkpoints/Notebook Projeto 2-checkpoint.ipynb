{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 de Ciência de dados:\n",
    " \n",
    " \n",
    " #### Introdução:\n",
    "  Este projeto objetifica a tentativa de criação de um modelo de predição cuja variável de interesse é o Rating que um aplicativo da PlayStore recebe, de acordo com algumas caraceterísticas intrínsecas. O modelo fará isso utilizando um Dataset importado do Kaggle e um processe de regressão.\n",
    "  Este projeto objetifica a criação de um modelo capaz de prever o Rating de aplicativos da Google Playstore, baseando-se em outras características, como quantidade de reviews, categoria e preço. O modelo utilizará um Dataset importado do Kaggle e será realizado um processo de regressão.\n",
    " \n",
    " #### Link do dataset:\n",
    "  * https://www.kaggle.com/lava18/google-play-store-apps\n",
    " \n",
    "#### Integrantes:\n",
    "*  Jean Silas\n",
    "*  Isabelle Moschini\n",
    "*  Matheus Barros\n",
    "*  Rafael Monteiro\n",
    "\n",
    "#### Váriavel Target:\n",
    "   * Ratings (0 a 5)\n",
    "   \n",
    "   \n",
    "#### Features:\n",
    "   * Category\n",
    "   * Reviews\n",
    "   * Installs\n",
    "   * Price\n",
    "   * Content Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Importando as bibliotecas e lendo a base de dados (dataset) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo para começarmos a analisar o dataset é observar suas categorias e os tipos de elementos presentes em cada uma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as Bibliotecas:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "import sklearn \n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrindo o Dataset\n",
    "dataset = pd.read_csv('googleplaystore.csv')\n",
    "\n",
    "#Verificando suas dimensões\n",
    "print('Este dataset possui {} linhas e {} colunas'.format(dataset.shape[0],dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondando os dados\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondando os tipos de dados\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  _Como o modelo utilizará métodos de regressão, precisaremos fazer um tratamento dos dados e priorizar pela transformação do máximo de elementos possível em numéricos._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Pré-processamento de dados:\n",
    "\n",
    "  Após visualizar superficialmente os dados, vamos partir para a tratamento deles: vamos remover as colunas que não são interessantes a priori para a nosso modelo, remover espaços vazios e outros processos de limpeza.\n",
    "  \n",
    "  Nós não consideramos as colunas App, Size, Genres, Last Updated, Current Ver, Android Ver e Type interessantes para o modelo, uma vez que:\n",
    "  * App: irrelevante e cada aplicativo possuía um valor diferente;\n",
    "  * Size: como mostrado abaixo, a maioria dos dados tem valor \"Varies with device\", então essa categoria se torna irrelevante, pois grande parte dos valores, que deveriam ser numéricos, são desconhecidos;\n",
    "  * Genres: repetitivo com Category, varia em um espectro maior e cada aplicativo pode possuir mais de uma;\n",
    "  * Last Updated, Current Ver e Android Ver: seriam dados que precisariam de um tratamento e provavelmente não teriam muita influência sobre o modelo;\n",
    "  * Type: seria repetitivo com o Price, que abrange diversos valores por não ser categórico. De qualquer forma, é interessante notar que a grande maioria dos aplicativos é gratuito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = dataset.drop(columns=['App', 'Size', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver','Type'])\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_É importantíssimo remover as linhas que possuem valores vazios para que não ocorra nenhum problema no momento de passar os dados pelo modelo de predição._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estamos eliminando as linhas que possuem valores vazios\n",
    "data0 = data0.dropna()\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Uma vez retirado os valores nulos, vamos avaliar as frequências de cada variável, para assim entender como está o dataset e precisar os próximos passos de limpeza. Mas antes vamos tirar os cifões do coluna Price para e os \"+\" dos installs e transformar as variáveis Reviews, Installs e Price em númericas para poder aplicar as funções do Pandas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para tratar as colunas numéricas:\n",
    "\n",
    "#Definindo função que limpa\n",
    "def Price_clean(valor):\n",
    "    valor_str = str(valor)\n",
    "    return float(valor_str.replace('$', ''))\n",
    "\n",
    "#Definindo função que limpa e transforma em valor numérico\n",
    "def Installs_clean(valor):\n",
    "    valor_str = str(valor)\n",
    "    return int(valor_str.replace('+', '').replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando as funções definidas acima acima:\n",
    "data0.Price = data0.Price.astype(str).map(Price_clean)\n",
    "data0.Installs = data0.Installs.astype(str).map(Installs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando todos os valores numéricos em float\n",
    "data0.Reviews = data0.Reviews.astype('float64')\n",
    "data0.Installs = data0.Installs.astype('float64')\n",
    "data0.Price = data0.Price.astype('float64')\n",
    "data0.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0['Content Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Installs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1- Decisões sobre o dataset:\n",
    "    \n",
    "   Após entendermos mais os dados decidimos tomas as seguintes decisões:\n",
    "   \n",
    "   * Retirar todas as linhas que possuem \"Adults only 18+\" como característica da feature Content Rating, uma vez que só possuem 3 linhas em que ele aparece, sendo assim, um outlier para o nosso modelo;\n",
    "   \n",
    "   * Retirar todas as linhas que possuem \"Unrated\" como característica da feature Content Rating, uma vez que só possui uma linha em que ele aparece, sendo assim, um outlier para o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = data0.loc[data0['Content Rating'] != 'Adults only 18+', :]\n",
    "data0 = data0.loc[data0['Content Rating'] != 'Unrated', :]\n",
    "data0['Content Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2- Dados tratados para fazer uma análise mais aprofundada:\n",
    "\n",
    "   A partir desse ponto, já possuimos dados mais parecidos com o que usaremos no nosso modelo. Ess etapa inicial, consistiu em descartar dados que não são importantes para o modelo e para a análise exploratório e fazer a correção de dados necessária para a maior robustez do modelo e análise exploratória.\n",
    "   \n",
    "   * Váriavél Target:Rating\n",
    "   * Features: Category, Reviews, Installs, Price e Content Rating.\n",
    "   \n",
    "   * Tipagem das features:\n",
    "   \n",
    "       * quantititvas: Reviews, Installs e Price.\n",
    "       \n",
    "       * qualitativas:  Category e Content Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Analise exploratória do dataset:\n",
    "   _Como o nosso dataset possui tanto variáveis qualitativas quanto quantitivas então separaremos as análises que cabem a cada tipode variável._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Análise das variáveis quantitativas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entendendo as medidas das variáveis numéricas.\n",
    "data0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondado a distribuição de Rating\n",
    "plt.hist(data0.Rating,bins=42,edgecolor='white')\n",
    "plt.title(\"Histograma dos ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modelo aparenta ser uma distribuição normal, para isso verificaremos:\n",
    "stats.probplot(data0.Rating,dist=\"norm\",plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Com esse gráfico constatamos que a distribuição não é normal, e portanto nossa suposição estava errada_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.Rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Aqui, podemos perceber que o valor de Rating mais frequente é de 4.4, seguido de suas vizinhanças. Quanto mais distante desse valor, menor é a frequência._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondado a distribuição de Reviews\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(data0.Reviews,bins=42,edgecolor='white')\n",
    "plt.title(\"Histograma dos reviews\")\n",
    "plt.xlabel(\"Reviews\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(data0.Reviews,bins=42,edgecolor='white', range=[0, 1e3])\n",
    "plt.title(\"Histograma dos reviews\")\n",
    "plt.xlabel(\"Reviews\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Observando o primeiro gráfico, percebemos que Review está concentrado na vizinhança de um valor. Porém, reduzindo o intervalo analisado, notamos que os valores seguem alguma distribuição. Para verificar a situação, vamos analisar frequencia numericamente_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando o valor \n",
    "data0.Reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Os reviews não estão concentrados em um valor, mas sim em um intervalo_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondado a distribuição de Installs\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(data0.Installs,bins=42,edgecolor='white', range=[0, 1e9])\n",
    "plt.title(\"Histograma dos installs\")\n",
    "plt.xlabel(\"Installs\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(data0.Installs,bins=42,edgecolor='white', range=[0, 1e6])\n",
    "plt.title(\"Histograma dos installs\")\n",
    "plt.xlabel(\"Installs\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Analisando o primeiro histograma, verificamos que a variável install se concentra na vizinhança de um valor. Porém, considerando um intervalo menor dos valores (de 0 a 1 000 000), percebemos que os dados estão distribuídos de forma inconclusiva. Vamos tentar entender isso, verificando os valores numericamente_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondando a situação\n",
    "data0.Installs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A quantidade de installs mais frequente dos aplicativos é da orderm de 10^3._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sondado a distribuição de Price\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(data0.Price,bins=62,edgecolor='white')\n",
    "plt.title(\"Histograma dos prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(data0.Price,bins=62,edgecolor='white', range=[0, 10])\n",
    "plt.title(\"Histograma dos prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Assim como o Install, o Price se concentra na vizinhança de um valor, que neste caso seria o zero. Com isso, podemos supor que a grande maioria dos apps são gratuitos. Para verificar tal suposição, verificamos a frequência dessa variável numricamente_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a suposiçaõ anterior:\n",
    "data0.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem = len(data0.loc[data0.Price==0,:])/len(data0)\n",
    "print(\"Porcentagem de apps gratuitos é de : {}%\".format(porcentagem*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Com isso, confirmarmos a hipótese que grande parte dos aplicativos são gratuitos, já que 93% deles são Free_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando os gráficos\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(data0.Rating,bins=42,edgecolor='white',color='blue')\n",
    "plt.title(\"Histograma dos ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(data0.Price,bins=42,edgecolor='white',color='brown')\n",
    "plt.title(\"Histograma dos reviews\")\n",
    "plt.xlabel(\"Reviews\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(data0.Price,bins=42,edgecolor='white', color='red')\n",
    "plt.title(\"Histograma dos prices\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.hist(data0.Installs,bins=42,edgecolor='white', color='black')\n",
    "plt.title(\"Histograma dos installs\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Para entendermos ainda melhor essas 4 variáveis quantitavas, vamos plotar mais alguns gráficos:_\n",
    "   _Assim podemos entender, por exemplo, a questão dos outliers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.boxplot(column='Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.boxplot(column='Reviews');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.boxplot(column='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0.boxplot(column='Installs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os gráficos apresentam uma grande quantidade de outliers. No caso do Price, em especial, os valores se aglomeram próximos a zero por terem muitos aplicativos gratuitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_E para terminar a análise das variáveis quantitativas, vamos verificar a correlação entre elas:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando entre as variáveis quantitativas\n",
    "correl = pd.DataFrame.corr(data0)\n",
    "correl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando entre as variáveis quantitativas gráficamente\n",
    "sns.heatmap(correl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fim de melhor observar os dados, obtendo um gráfico mais disperso e de fácil análise e comparação, foi aplicado um logaritmo de base 10 nos dados quantitativos que não o Rating, que é o valor a ser previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0_log = data0.copy()\n",
    "data0_log['log_price'] = np.log(data0_log['Price'] + 1)\n",
    "data0_log['log_installs'] = np.log(data0_log['Installs'])\n",
    "data0_log['log_reviews'] = np.log(data0_log['Reviews'])\n",
    "data0_log = data0_log.drop(columns=['Price', 'Installs', 'Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando Graficamente:\n",
    "sns.pairplot(data0_log);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao observar os gráficos de Price, percebemos que, em geral, os dados se agrupam em três partes diferentes: os aplicativos gratuitos ou muito baratos, os aplicativos muito caros e os aplicativos de preço mediano. Analisando-os, notamos que há uma pequena relação entre os Ratings e os preços, afinal, há uma tendência a aplicativos pagos terem avaliações acima da 2.5, porém não há uma relação direta entre esses valores. Os aplicativos gratuitos se distribuem por todos os Ratings, aparentemente sem um padrão.\n",
    "\n",
    "Em relação aos Installs, este parece ter uma relação linear com os Reviews, o que faz sentido, pois quanto mais downloads um aplicativo possui, provavelmente mais avaliações terá. Ele também parece se relacionar com os Ratings, pois aplicativos com muitos downloads tendem a ter Ratings maiores, mais próximos de 5.0. \n",
    "\n",
    "Um comportamento muito semelhante ocorre com o gráfico dos Reviews em relação ao Rating, porém ainda mais acentuado, pois os aplicativos com muitas Reviews costumam ter um Rating muito próximo do valor máximo.\n",
    "\n",
    "\n",
    "Porém, devido aos diferentes grupos identificados nos gráficos de Price, optamos por utilizar apenas os aplicativos gratuitos, pois, como visto anteriormente, englobam a maioria dos apps, representando cerca de 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = data0_log.loc[data0_log.log_price == 0,:]\n",
    "sns.pairplot(data0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após verificarmos que os aplicativos pagos foram retirados, deixamos de analisar a coluna que envolve os preços no modelo, pois ela não interferiria mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = data0.drop(columns=['log_price'])\n",
    "sns.pairplot(data0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2- Conclusões a respeito da análise exploratória das variáveis quantitivas:\n",
    "\n",
    "   O que se percebe é que a nossa variável target não é muito bem explicada pelas variáveis quantitaivas, o que pode ser ruim para o modelo mais a frente, já que a baixa correlação entre as features e o target pode resultar num modelo que não é eficiente e que não preve o que ele foi criado para prever. Nos resta entender como as variáveis qualitativas se correlacionam com a variável Target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3-Análise exploratória: entendendo os dados qualitativos\n",
    "   _Agora analisaremos as váriaveis qualitativas: Category e Content Rating_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a frequência de cada classe de Category:\n",
    "data0.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a frequência de cada classe de Content Rating:\n",
    "data0['Content Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a frequência de cada classe de Category graficamente\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.countplot(data0.Category);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a frequência de cada classe de Content Rating graficamente\n",
    "sns.countplot(data0['Content Rating']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =['Everyone','Teen','Mature 17+','Everyone 10+']\n",
    "colors = ['red','orange','green','blue']\n",
    "i = 0\n",
    "for label in labels:\n",
    "    data = dataset.loc[dataset['Content Rating']==label,:]\n",
    "    data = data['Rating']\n",
    "    plt.hist(data,bins=42, label=label,color=colors[i], edgecolor='white')\n",
    "    plt.legend()\n",
    "    plt.xlabel('\\nRating')\n",
    "    plt.ylabel('Contagem de Rating\\n')\n",
    "    plt.title('\\nRating por {}\\n'.format(label))\n",
    "    plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =['FAMILY','GAME','TOOLS','PRODUCTIVITY','MEDICAL','COMMUNICATION','FINANCE','SPORTS','PHOTOGRAPHY','LIFESTYLE','PERSONALIZATION','BUSINESS','HEALTH_AND_FITNESS','SOCIAL','SHOPPING','NEWS_AND_MAGAZINES','TRAVEL_AND_LOCAL','DATING','BOOKS_AND_REFERENCE','VIDEO_PLAYERS','EDUCATION','ENTERTAINMENT','MAPS_AND_NAVIGATION','FOOD_AND_DRINK','HOUSE_AND_HOME','WEATHER','AUTO_AND_DEMO','LIBRARIES_AND_DEMO','ART_AND_DESIGN','COMICS','PARENTING','EVENTS','BEAUTY']\n",
    "colors = ['red','orange','green','blue']\n",
    "i = 0\n",
    "for label in labels:\n",
    "    data = dataset.loc[dataset['Category']==label,:]\n",
    "    data = data['Rating']\n",
    "    plt.hist(data,bins=42, label=label,color=colors[i], edgecolor='white')\n",
    "    plt.xlabel('\\nRating')\n",
    "    plt.ylabel('Quantidade de aplicativos\\n')\n",
    "    plt.title('\\nRating por {}\\n'.format(label.lower()))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    i+=1\n",
    "    i = i%4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise dos dados qualitativos, chegou o momento de tranformá-los em dados numéricos, por meio dos dummies. Afinal, por estarmos utilizando um modelo de regressão, é necessário estabelecer como input apenas dados quantitavos.\n",
    "\n",
    "O processo de transformação de variáveis qualitativas para variáveis dummy se dá por meio da alocação de cada classe da feature em questão e valores de 0 e 1. Cada classe dessa feature se torna uma coluna nova, em que a classe correspondente à linha em questão assuma o valor 1, e todas as outras colunas a essa linha tenham valor 0.\n",
    "\n",
    "Um adendo: quando a feature possui k classes, o valor de colunas geradas ideal é k - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos transformar as variáveis catégoricas em dummies:\n",
    "df_d = pd.get_dummies(data0, columns=['Category','Content Rating','log_installs'], drop_first=True)\n",
    "print('Este dataset possui {} linhas e {} colunas'.format(df_d.shape[0],df_d.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro processo de regressão pelo qual nosso dataset irá passar é o de regressão linear (linear regression).\n",
    "\n",
    "Primeiramente, utilizamos o método de regressão linear. Esse método consiste em associar uma variável dependente Y em função de uma ou mais variáveis independentes X. Assim, pode-se estabelecer uma função de primeiro grau a fim de resumir essa relação e que possa ser utilizada para predizer os valores de Y.\n",
    "\n",
    "Para calcular os coeficientes dessa reta, é necessário utilizar o Método dos Mínimos Quadrados (MMQ). Tal método busca o melhor valor que os coeficientes possam atingir, de maneira que a diferença entre o valor predito pela função e o valor real, seja a menor possível.\n",
    "\n",
    "Dessa forma, ao observarmos que existia uma relação em um diagrama de dispersão entre o Rating e os Installs e Reviews, optamos por utilizar a regressão linear para fazer previsões a partir dos dados.\n",
    "\n",
    "A Variável dependente (Y) é a variável que queremos prever, que corresponde ao Rating dos aplicativos no caso do nosso projeto. Já as variáveis independentes (X), são aquelas que podem influenciar na variável que será prevista. Nesse caso, serão todas as informações do nosso DataSet, ou seja, Installs, Reviews, Category, entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando função do modelo por regressão linear\n",
    "def regress(Y,X):\n",
    "    '''\n",
    "    Y: coluna do DataFrame utilizada como variável resposta (TARGET)\n",
    "    X: coluna(s) do DataFrame utilizadas como variável(is) explicativas (FEATURES)\n",
    "    '''\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = df_d.loc[:7800,:]\n",
    "test = df_d.loc[7801:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_['Rating']\n",
    "X = train_.drop(columns=['Rating'])\n",
    "Ytest = test['Rating']\n",
    "Xtest = test.drop(columns=['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = regress(Y,X)\n",
    "\n",
    "pre = results.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefb = results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Apresentando os resultados\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tirar alguma conclusão sobre a eficácea desse modelo, optamos por observar o valor de 'R-Squared', que representa um valor entre 0 e 1, sendo melhor quanto mais próximo do valor máximo. No caso do nosso modelo, esse valor é de 0.191, o que é baixo. \n",
    "\n",
    "Portanto, podemos concluir que a regressão linear não é o melhor método para tentar prever o Rating dos aplicativos baseado no dataset utilizado. Outra hipótese seria que o Rating dos aplicativos, considerando os demais dados apresentados, é imprevisível.\n",
    "\n",
    "Assim, decidimos utilizar outro método para regressão, o Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest é uma técnica usada em machine learning, pode ser aplicada tanto em regrassão quanto classificação, no nosso caso usamos regressão por se tratar de um modelo quantitativo.\n",
    "\n",
    "A aplicação da técnica é similar à um processo de decisão em conjunto em que o dataset é percorrido por diferentes caminhos resultando em um valor por àrvore, posteriormente sendo combinadas múltiplas árvores de decisão e tirado a média entre elas a fim de ter um resultado fiel ao dataset analisado.\n",
    "\n",
    "É recomendado que os valores analisados não sejam inviesados, caso os tenha é muito provável que a análise retornara um valor promissor no entanto por ser ilusório pois as árvores acabaram tomando o mesmo caminho diversas vezes devido à maior concentração em um determinado valor.\n",
    "\n",
    "Tomamos certas precauções para que os valores do dataset sejam realocados nas árvores de maneira eficiente e que o resultado seja mais próximo da realidade, seguindo essa linha definimos a quantidade de estimadores à aproximadamente 100 que não é um valor exacerbado, utilizamos logaritmo para os valores de review e installs, e limitamos a análise para apenas os aplicativos gratuitos, para melhor compreensão e análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando o modelo por Random Forest\n",
    "model = RandomForestRegressor(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a variável que prevê o valor do Rating, baseando-se nas demais características do teste\n",
    "Ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar a performance de nosso modelo com Random Forest, usamos a função .score(). Primeiro, comparamos o valor previsto pelo modelo com o esperado pelo conjunto de treino, usando X e Y de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, usamos o score() novamente, dessa vez para comparar o valor previsto pelo modelo com o esperado, no conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na função .score(), quanto mais próximo de 1 o resultado, mais eficiente é o modelo dado o dataset utilizado. No primeiro caso, o valor está relativamente próximo de 1.0, porém, no segundo, está bem distante (inclusive, é negativo).\n",
    "\n",
    "Essa enorme diferença revela, portanto, que o modelo tem um problema de Overfitting. Ou seja, ele é capaz de prever valores bem próximos aos reais utilizando dados do treino, porém é incapaz de fazer boas previsões com valores nunca antes vistos, que é o caso do teste.\n",
    "\n",
    "A fim de verificar a eficiência desse modelo na predição, utilizamos outros métodos, como o R Squares, que também foi utilizado na Regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (sklearn.metrics.mean_squared_error(Ytest, Ypred))**(1/2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa verificação aponta que o modelo não está tão ruim quanto a verificação anterior. Afinal, o valor apontado é de mais de 0.6 sendo que o maior possível  e o melhor de 1.0.\n",
    "\n",
    "Porém, antes de chegar a qualquer conclusão, é importante verificar essa eficiência de outras formas, como utilizando os resíduos, que demonstram a diferença entre o valor do Rating previsto pelo modelo e o real, apontado nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = Ytest - Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuos, bins=50);\n",
    "plt.title('Histograma dos resíduos do Rating\\n')\n",
    "plt.ylabel('Contagem dos resíduos\\n')\n",
    "plt.xlabel('\\nValor dos resíduos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos.std(ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o histograma plotado, podemos perceber que há diferenças consideráveis entre os valores (chegando até mais de 2, em módulo, em alguns casos). Afinal, o valor de Rating varia entre 0 e 5 apenas, o que significa que há um desvio padrão alto, de cerca de 12% em relação aos valores possíveis.\n",
    "\n",
    "Então, plotamos histogramas e um gráfico de correlação a fim de comparar o Rating previsto pelo modelo com seus valores presentes nos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Ytest, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Ypred, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparação numérica entre os valores de Rating do teste e previsto pelo modelo.\n",
    "#Quanto mais próximo de 1, melhor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De início, nossa intenção era, com base nos dados do dataset, estipular o Rating dos aplicativos do Google Playstore. Ao decorrer do projeto, nos deparamos com certas variáveis que não possuíam uma correlação clara e interessante para prever os valores desejados.\n",
    "\n",
    "Durante o processo, realizamos um pré-processamento dos dados do dataset, fizemos uma análise exploratória deles, comparamos as características escolhidas por meio de gráficos, transformamos variáveis qualitativas em dummies e utilizamos o log para deixar as variáveis em uma escala mais conveniente para fazermos as análises.\n",
    "\n",
    "Por fim, realizamos um modelo por Regressão Linear, que não se mostrou eficiente em prever o Rating. Então, optamos por utilizar um modelo de regressão com Random Forest, que também foi incapaz de realizar boas previsões.\n",
    "\n",
    "Com isso, nós concluímos que, baseando-se apenas nas características presentes no dataset utilizado e escolhidas para o nosso modelo, o valor do Rating é imprevisível. Afinal, não foi possível relacioná-lo de maneira direta a nenhuma variável analisada nesse projeto, portanto ele provavelmente se relaciona a diversas outras variáveis externas não presentes nesse dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências:\n",
    "* https://escholarship.org/uc/item/35x3v9t4\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "* https://medium.com/data-hackers/implementando-regress%C3%A3o-linear-simples-em-python-91df53b920a8\n",
    "* http://www.uel.br/pessoal/lscunha/pages/arquivos/uel/Economia%20Noturno%202018/Aula%207%20-%20Regress%C3%A3o%20Linear%20M%C3%BAltipla.pdf\n",
    "* https://stattrek.com/multiple-regression/dummy-variables.aspx\n",
    "* https://medium.com/@alegeorgelustosa/an%C3%A1lise-explorat%C3%B3ria-e-preditiva-do-dataset-titanic-em-python-fbd5e5bb7328\n",
    "* https://www.youtube.com/watch?v=0s_1IsROgDc\n",
    "* https://medium.com/swlh/random-forest-and-its-implementation-71824ced454f\n",
    "* https://medium.com/towards-artificial-intelligence/exploratory-data-analysis-in-python-ebdf643a33f6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participação de cada membro do grupo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No começo do trabalho a equipe toda se manejou para procurar a temática do que seria analisado, tivemos em mente alguns temas e acabamos escolhendo em equipe \"aplicativos da google play\" a fim de descobrir o rating baseado no que o dataset tinha disponível.\n",
    "\n",
    "\n",
    "\n",
    "Acabamos tendendo à regressão por se tratar de um valor analisado quantitativo.\n",
    "\n",
    "\n",
    "\n",
    "Primeiramente a Isabelle compartilhou a tela e em conjunto com os outros integrantes extraiu o dataset e começou a fazer o cleanup dos dados, dropamos coisas desnecessárias como tamanho do arquivo (pois variava de acordo com o dispositivo), versão, nome e gênero.\n",
    "\n",
    "\n",
    "\n",
    "Paralelamente o Jean pegou os valores já limpos, fez a implementação dos gráficos de análise exploratória e começou a introdução de transformar as variáveis categóricas em Dummies.\n",
    "\n",
    "\n",
    "\n",
    "Isabelle, Rafael e Matheus analisaram os passos feitos pelo Jean explicando verificando certas partes da análise exploratória e mudando alguns dos gráficos a fim de melhor analisá-los, como por exemplo ajustar alguns eixos.\n",
    "\n",
    "\n",
    "\n",
    "Jean compartilhou a tela e em conjunto foi incializado a primeira implementação de regressão linear com os dados da análise exploratória.\n",
    "\n",
    "\n",
    "\n",
    "Matheus compartilhou a tela e em conjunto foi analisado os resultados da regressão linear e verificação da eficácia do modelo, foi então tomado um consenso, junto com o professor Ayres, de se tentar por meio de um modelo random forest para ver se previsão iria melhorar.\n",
    "\n",
    "\n",
    "\n",
    "Rafael compartilhou a tela junto com o grupo, foi mudadoi alguns valores a fim de melhorar a análise, melhor implementação da regressão linear e foi constatado que mesmo com as coisas tomadas não era possível definir Rating com base nos dados que nós analisamos.\n",
    "\n",
    "\n",
    "\n",
    "Isabelle compartilhou a tela, foi feito o filtro de valores como installs e reviews usando logaritmo, indpendente dos casos foi impossibilitado definir o rating com base nas variáveis analisadas.\n",
    "\n",
    "\n",
    "\n",
    "Rafael, Isabelle, Jean e Matheus olharam as rúbricas expostas no excel e separaram as coisas que faltava para atingir conceito A, cada um ficou responsável por uma parte:\n",
    "* Rafael, explicação linear regression.\n",
    "* Isabelle, manejamento do jupyter e explicação de partes que faltavam.\n",
    "* Matheus, explicação do random forest.\n",
    "* Jean, comparação das variáveis qualitativas com a target.\n",
    "\n",
    "\n",
    "\n",
    "Por fim todos os membros discutiram e decidiram a conclusão do projeto.\n",
    "\n",
    "\n",
    "\n",
    "Agradecimento ao Maciel e Ayres por nos ajudarem nas situações de dificuldade, ajudaram bastante na implementação dos modelos e fizeram a gente tomar consciência de certos pontos do nosso trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
